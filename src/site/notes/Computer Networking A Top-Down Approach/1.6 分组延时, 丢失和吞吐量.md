---
{"created":"2025-09-24T19:34","updated":"2025-12-27T11:42","dg-publish":true,"permalink":"/Computer Networking A Top-Down Approach/1.6 分组延时, 丢失和吞吐量/","dgPassFrontmatter":true,"noteIcon":""}
---

> 这里涉及到原书1.4 Delay, Loss and Throughput in Packet-Switched Networks
> // 【2025.12.26 读原书 补】

之前我们学过了数据交换的方式，有链路交换和分组交换，当然我们前面讲了链路交换不太适合计算机之间的通信，我们一般是采用的分组交换，当然，分组交换为了按需使用也付出了一定的代价，其中一些代价就是会发生延时和丢失
this lecture就是讲分组时延，丢失，吞吐量这些指标
### 分组丢失和延时是怎么怎么发生的？
![Pasted image 20250924194305.png|500](/img/user/accessory/Pasted%20image%2020250924194305.png)
路由器的每个链路都会有一个队列，当一个分组到达的时候，路由器会查询对应的路由表，找到要分到的链路，并将分组扔进这个链路的队列
如果队列中已经有分组了，那就要排队，这就是一个延时，这个叫排队延时
如果队列中已经满了，溢出了，那么这个分组就会被丢弃掉，这就是分组的丢失
这里有一个问题是为什么要排队？ -- 因为链路的传输能力小于到来的分组
那为什么不把队列弄大一些，这样就不会丢失了？ -- 这样排队延时会很大，响应时间太长了

### 四大延时
![Pasted image 20250924194817.png|500](/img/user/accessory/Pasted%20image%2020250924194817.png)
**处理延时**
当一个分组到达的时候，需要检查这个分组是否出错了，需要将这个分组的ip提取出来查路由表，还要对一些字段做一些处理(后面会讲)，这些操作都需要时间，这被称为处理延时
**排队延时**
查完路由表决定从某条链路放出去，如果队列中有其他的分组，那就要经历排队延时
**传输延时(发送延时)**
分组通过链路放出去，是一个bit一个bit往外打的
传输一个字节的时间？ 如果带宽为R(bps)，那么传输一个bit的时间就是$\frac{1}{R}$,如果数据的长度是L个bit，那么传输的时间就是$\frac{L}{R}$
从第一个bit打出去开始，到所有bit打完，叫传输延时
**传播延时**
bit在链路上所经过的时间叫做传播延时，d为距离，s为速率，传播延时为$\frac{d}{s}$
![Pasted image 20250917203623.png|300](/img/user/accessory/Pasted%20image%2020250917203623.png)

> [!quote] Transmission Delay v.s. Propagation Delay
> 原书给出了一个TransmissionDelay 和 Propagation Delay的比较, 说的很明白了
> The transmission delay is the amount of time required for the routher to push out the packet; it is a function of the packet's length and the transmission rate of the link, but has nothing to do with the distance the two routers.
> transmission delay is $\frac{L}{R}$, packet L bits, transmisson rate of the link from router A to router B by R bits/sec.
> The propagation delay, is the time it takes a bit to propagate from one router to the nest; it is a function of the distance between the two routers, but has nothing to do with the packet's length or the transmission rate of the link.
> propagation delay is $\frac{d}{s}$, d is the distance between router A and router B and s is the propagation speed of the link(meters/sec).
> // 【2025.12.26 读原书 补】

> [!quote]
> 原书中强调，this situation arises in packet-switched networks -- the first bits in a packet can arrive at a router while many of the ramaining bits in the packet are still waiting to be transmitted by the preceding router.
> 其实这一点在上面老师话的那个图里就很直观的能感受到
> // 【2025.12.26 读原书 补】

> [!quote] total nodal delay
> ![Pasted image 20251226103756.png|500](/img/user/accessory/Pasted%20image%2020251226103756.png)
> // 【2025.12.26 读原书 补】

### 排队延时的影响因素
排队延时取决于流量强度
$I=\frac{La}{R}$ , 其中R是带宽，L是分组的长度，a是单位时间系统通过链路的分组个数，La就是单位时间通过链路放出去的比特的数量，La和R是一个量纲
研究表明，流量强度越接近于1，排队延时越接近于无穷大
> [!quote] 排队延时的影响因素 & 流量强度
> 原书中说排队延时不同于其他三个延时，排队延时因packet各异，一个简单的例子就是一口气向empty queue中打10个packet，第一个packet的排队延时就为0，最后一个的排队延时就比较长
> 原书中给出了一些表征排队延时的指标，average queuing delay(平均排队延时), variance of queuing delay(排队延时方差), the probability that the queuing delay exceeds some specified vlaue(排队延时超过特定值的概率) ...
> 重点介绍的一个指标叫**traffic intensity(流量强度)**:$\frac{La}{R}$
> 原书先分析了 La/R >1 的情况：If La/R > 1, then the average rate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted from the queue.（数据位到达队列的平均速率超过从队列传输数据位的速率）-> Design your system so that the traffic intensity is no greater than 1.
> 对于La/R < 1的情况：
> 原书首先分析了周期性(periodically)的情况:
> 如果是one packet arrives every L/R seconds, 那对于一个emety queue来说就是no queuing delay.
> 如果packets arrive in bursts but periodically(突发但周期性的方式), example suppose N packets arrive simulaneously every (L/R)N seconds： 那么在这N个packet中第一个packet是no queuing delay的，往后一个都得多等L/R秒，原书是要求我们自己算average queuing delay，计算结果：
> $$
> \frac{0+\frac{L}{R}+\frac{2L}{R}+...++\frac{(N-1)L}{R}}{N}
> =\frac{N(N-1)L}{2R}
> $$
> 对于random的情况，流量强度仍然具有一定的价值和规律
> 
> ![Pasted image 20251226143038.png|400](/img/user/accessory/Pasted%20image%2020251226143038.png)
> // 【2025.12.26 读原书 补】


### End-to-End Delay(2025.12.26看原书补)
> [!note] End-to-End Delay 整理
> 下面这个图是我根据之前中科大郑烇老师课上画的那个图稍微改了一下，把所有的延时都简单的表示进去了：
> ![Pasted image 20251226122532.png|500](/img/user/accessory/Pasted%20image%2020251226122532.png)
> 我画的是电路交换或者是一个packet的一种情况
> 要注意区分传播时延和发送时延（前面辨析过）
> 对于PC发送一个packet到第一个路由器来说，如果只看传播时延和发送时延，整个packet到达的时间应该可以看做是PC打出整个分组的时间(即发送时延)+最后一个bit到达第一个路由器的时间(即传播时延) 或者 第一个路由器收到第一个bit的时间(即传播时延)以及收完整个packet的时间(即发送时延)
> 如果考虑N条链路，我们先考虑**同质**的情况，即n段链路的transmission rate和propagation speed是不变的
> 1个packet：
> - 发送延时即$\frac{NL}{R}$
> - 传播时延：N段链路，所以$\frac{Nd}{s}$
> - 处理时延是N个，因为N段链路，从设备打出了N次 ？ 最后一个设备要验证算处理嘛？
> - 排队时延: N-1个路由器 N-1个排队时延
> 
> 
> 如果考虑P个packet
> - 发送时延在[[Computer Networking A Top-Down Approach/1.3 网络核心\|1.3 网络核心]]推导过：$=\frac{(N+P-1)L}{R}$ 这是由于存储–转发机制和流水线效应的存在。第一个分组需要依次在所有 N 条链路上传输，因此其到达目的节点所需的时间为 $\frac{NL}{R}$​。当第一个分组到达最后一个节点时，第二个分组已经完成了前 N−1 条链路的传输并到达倒数第二个节点。此时，第二个分组仍需在最后一条链路上进行一次传输，其传输时延为 $\frac{L}{R}$​。在这段时间内，第三个分组到达倒数第二个节点。依此类推，由于流水线传输，每增加一个分组，目的节点接收到分组的时间仅增加一个 $\frac{L}{R}$此类推... 总共P-1个
> - 传播时延：还是N段链路还是$\frac{Nd}{s}$ ： 这个传播时延只与链路长度和propagation speed有关
> 
> $$
> d_{\text{end-end}}^{(P)}
> =
> \underbrace{
> N d_{\text{proc}}
> +
> (N-1) d_{\text{queue}}
> +
> N d_{\text{prop}}
> }_{\text{非传输时延（不随 }P\text{ 线性增长）}}
> +
> \underbrace{
> (N + P - 1)\frac{L}{R}
> }_{\text{传输时延（流水线效应）}}
> $$
> 
> 
> 对于**异质链路**：如果有N条链路(link 1 to link N)，N-1个路由器，N+1个设备(从0开始编号)，异质链路 
> 1个packet考虑end-to-end daly应该是这样的:
> $$
> d_{\text{end-end}}
> =
> \underbrace{
> \sum_{i=0}^{N-1} d_{\text{proc}}^{(i)}
> }_{\text{处理时延（源主机 + 路由器）}}
> +
> \underbrace{
> \sum_{i=1}^{N-1} d_{\text{queue}}^{(i)}
> }_{\text{排队时延（仅路由器）}}
> +
> \underbrace{
> \sum_{i=1}^{N} \frac{L}{R_i}
> }_{\text{传输时延（}N\text{ 条链路）}}
> +
> \underbrace{
> \sum_{i=1}^{N} d_{\text{prop}}^{(i)}
> }_{\text{传播时延（}N\text{ 条链路）}}
> $$
> p个packet呢？(有点复杂了 没想明白 这是chatGPT给我的)
> $$
> d_{\text{end-end}}^{(P)}
> =
> \underbrace{
> \sum_{i=0}^{N-1} d_{\text{proc}}^{(i)}
> +
> \sum_{i=1}^{N-1} d_{\text{queue}}^{(i)}
> +
> \sum_{i=1}^{N} \frac{L}{R_i}
> +
> \sum_{i=1}^{N} d_{\text{prop}}^{(i)}
> }_{\text{第一个 packet 的端到端时延}}
> +
> \underbrace{
> (P-1)\frac{L}{R_{\min}}
> }_{\text{流水线效应（瓶颈链路）}}
> $$
> 
> 但其实很多时候我们都是再算发送实验和传播时延，排队时延和处理时延的总时间一般题目会直接告诉，并且大多数都是同质的，所以最后其实考试的话公式只是一个简单的特殊情况：
> $$
> d_{end-end}=N\frac{d}{s}+\frac{(N+P-1)L}{R}+d_{sum-proc}+d_{sum-queue}
> $$
> // 【2025.12.26 读原书 补】


### Internet的延时和路由？
可以通过tranceroute(Linux)诊断程序，来看一下延时
![Pasted image 20250924204623.png|500](/img/user/accessory/Pasted%20image%2020250924204623.png)
tranceroute的原理是发送3个分组
第一跳的往返延时，第二跳的往返延时...
他利用了一个协议叫做ICMP协议(互联网控制报文协议)
![Pasted image 20250924205736.png|500](/img/user/accessory/Pasted%20image%2020250924205736.png)
A向B传输的分组中，有一个头部，其中有一个字段叫做TTL(生存时间)，在A放出这个分组的时候TTL是个有效值，然后每经过一跳TTL就会减1，当TTL减为0的时候，这个路由器会给A发送一个消息说由于它的TTL为0了，所以扔掉了，并告知ip地址(我干的hhh)，所以就形成了上面我们看到的IP地址和延时的测量
那怎么知道走到头了呢？ 是TTL会设置一个很大值，到达目标B的时候，会解析这个分组，它其中所包含的目标的端口号，实际上B中并没有应用进程守候在这个端口，所以B会给A回一个目标端口不可达

### 分组丢失了怎么办？
实际上分组丢失了有三种情况
- 如果这条链路本身就是可靠的，是由上个节点重传
- 如果这条链路是不可靠的
	- 可能是由源主机重传
	- 如果是UDP，那丢了就是丢了，不重传

### 吞吐量
吞吐量指的是单位时间内，从原主机向目标主机发出去的有效的比特的数量
吞吐量有两种，一种是瞬间的，一种是平均的
- 瞬间吞吐量:在一个时间点的速率
- 平均吞吐量:在一个长时间内平均

> [!quote] 瞬时吞吐量 & 平均吞吐量
> 原书：
> The instantaneous throughput at any instant of time is the rate (in bits/sec) at which Host B is recceiving the file.
> If the file consists of F bits and the transfer takes T seconds for Host B to receive all F bits, then the average throught of the file transfer is F/T bits/sec.
> // 【2025.12.27 读原书补】


短板效应
![Pasted image 20250924211148.png|500](/img/user/accessory/Pasted%20image%2020250924211148.png)

> [!quote] 短板效应
> 
> ![Pasted image 20251227112342.png|400](/img/user/accessory/Pasted%20image%2020251227112342.png)
> 我感觉这里老师的那张图更形象。
> 不过原书中有一句话把问题核心给阐释了： we may think of bits as fluid and communication links as pipes. Clearly, the server cannot dump bits through its link at a rate faster than $R_s$ bps; and the router cannot forward bits at a rate faster than $R_c$ bps.
> 并且原书中推广到了n段链路，其实都是一样的，核心就在于 bottleneck link (瓶颈电路)
> 并且原书中说有了throughout，就可以求approximate transfer time: $F/min\{ R_s,R_c \}$ 而且书中也强调了这只是近似值: these expressions for throughput and transfer time are only approximations, as they do not account for store-and-forward and processing delays as well as protocol issues.
> // 【2025.12.27 读原书补】


**带宽vs.吞吐量？**
可以认为带宽是理论值，吞吐量是实际值

**实际中的吞吐量**
实际上一条链路并不只有两个主机使用的，可能由十个主机对的通信在使用这段电路，那实际上其中两个主机只能用带宽的十分之一
可能传输的时候要占用全部带宽，但是平均下来要排队，所以只会用十分之一
所以实际上的瓶颈电路取决于这$\frac{1}{n'}$,所有链路上平均下来最小的那个带宽

> [!quote] 实际中的吞吐量
> ![Pasted image 20251227113035.png|450](/img/user/accessory/Pasted%20image%2020251227113035.png)
> 
> 图a: today, the core of the Internet is over-provisioned with high speed links that experience little congestion -- In fact, thourghput = $min\{R_s,R_c\}$ -- the constraning factor for throughput in today's Internet is typically the access network.
> 更一般的情况实际上是图b的情况，10个clients从10个server上下载文件，并且公用同一条bottleneck link
> If the rate of the common link, R, is large -- say a hundred times large than both $R_s$ and $R_c$ : 那实际上还是a图的情况，throughout还是$min\{R_s,R_c\}$
> 但如果是same order(同一量级), the common link divides its transmission rate equally among the 10 downloads!
> // 【2025.12.27 读原书补】
